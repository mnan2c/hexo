title: Elasticsearch V7.0

tags:
  - 类库&中间件

categories:
  - 类库&中间件

---
## 1. 简介
Elasticsearch 是一个开源的搜索引擎，建立在一个全文搜索引擎库 Apache Lucene基础之上。

Elasticsearch 是使用 Java 编写的，它的内部使用 Lucene 做索引与搜索，但是它的目的是使全文检索变得简单， 通过隐藏 Lucene 的复杂性，取而代之的提供一套简单一致的 RESTful API。

Elasticsearch 不仅仅是 Lucene，并且也不仅仅只是一个全文搜索引擎。 它可以被下面这样准确的形容：
- 一个分布式的实时文档存储，每个字段 可以被索引与搜索
- 一个分布式实时分析搜索引擎
- 能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据
- 天生就是分布式的：它知道如何管理节点来提供高扩展和高可用。

## 2. 基本概念
- 集群（Cluster）一组拥有共同的 cluster name 的节点。
- 节点（Node) 集群中的一个 Elasticearch 实例。
- 索引（Index) 相当于关系数据库中的database概念，一个集群中可以包含多个索引。这个是个逻辑概念。
- 主分片（Primary shard） 索引的子集，索引可以切分成多个分片，分布到不同的集群节点上。分片对应的是 Lucene 中的索引。
- 副本分片（Replica shard）每个主分片可以有一个或者多个副本。
- 类型（Type）相当于数据库中的table概念，mapping是针对 Type 的。同一个索引里可以包含多个 Type。
- Mapping 相当于数据库中的schema，用来约束字段的类型，不过 Elasticsearch 的 mapping 可以自动根据数据创建。
- 文档（Document) 相当于数据库中的row。
- 字段（Field）相当于数据库中的column。
- 分配（Allocation） 将分片分配给某个节点的过程，包括分配主分片或者副本。如果是副本，还包含从主分片复制数据的过程。

```
Relational DB -> Databases -> Tables -> Rows -> Columns
Elasticsearch -> Indices   -> Types  -> Documents -> Fields
```

## 3. 分布式集群
分布式系统要解决的第一个问题就是节点之间互相发现以及选主的机制。 Elasticsearch不用预先依赖一个服务发现的集群。
### 3.1 分片及副本
分布式存储系统为了解决单机容量以及容灾的问题，都需要有分片以及副本机制。Elasticsearch 没有采用节点级别的主从复制，而是基于分片。它当前还未提供分片切分（shard-splitting）的机制，只能创建索引的时候静态设置。

### 3.2 恢复以及容灾
Elasticsearch的恢复流程大致如下：
1. 集群中的某个节点丢失网络连接
2. master提升该节点上的所有主分片在其他节点上的副本为主分片
3. cluster集群状态变为 yellow ,因为副本数不够
4. 等待一个超时设置的时间，如果丢失节点回来就可以立即恢复。如果该分片已经有写入，则通过translog进行增量同步数据。
5. 否则将副本分配给其他节点，开始同步数据。

### 3.3 集群健康
在Elasticsearch集群中可以监控统计很多信息，但是只有一个是最重要的：集群健康(cluster health)。集群健康有三种状态：green、yellow或red。
- green	所有主要分片和复制分片都可用
- yellow	所有主要分片可用，但不是所有复制分片都可用
- red	不是所有的主要分片都可用

## 3.4 增加故障转移
在单一节点上运行意味着有单点故障的风险——没有数据备份。幸运的是，要防止单点故障，我们唯一需要做的就是启动另一个节点。`可以使用与第一个节点相同的方式启动第二个节点，而且命令行在同一个目录——一个节点可以启动多个Elasticsearch实例。
只要第二个节点与第一个节点有相同的cluster.name（请看./config/elasticsearch.yml文件），它就能自动发现并加入第一个节点所在的集群。`

第二个节点已经加入集群，三个复制分片(replica shards)也已经被分配了——分别对应三个主分片，这意味着在丢失任意一个节点的情况下依旧可以保证数据的完整性。

文档的索引将首先被存储在主分片中，然后并发复制到对应的复制节点上。这可以确保我们的数据在主节点和复制节点上都可以被检索。

## 3.5 横向扩展
如果我们启动第三个节点，我们的集群会重新组织自己，包含3个节点的集群——分片已经被重新分配以平衡负载。

Node3包含了分别来自Node 1和Node 2的一个分片，这样每个节点就有两个分片，和之前相比少了一个，这意味着每个节点上的分片将获得更多的硬件资源（CPU、RAM、I/O）。

分片本身就是一个完整的搜索引擎，它可以使用单一节点的所有资源。我们拥有6个分片（3个主分片和三个复制分片），最多可以扩展到6个节点，每个节点上有一个分片，每个分片可以100%使用这个节点的资源。

## 3.6 更多扩展
主分片的数量在创建索引时已经确定。然而，主分片或者复制分片都可以处理读请求——搜索或文档检索，所以数据的冗余越多，我们能处理的搜索吞吐量就越大。

复制分片的数量可以在运行中的集群中动态地变更，这允许我们可以根据需求扩大或者缩小规模。让我们把复制分片的数量从原来的1增加到2：
```js
PUT /blogs/_settings
{
   "number_of_replicas" : 2
}
```
blogs索引现在有9个分片：3个主分片和6个复制分片。这意味着我们能够扩展到9个节点，再次变成每个节点一个分片。这样使我们的搜索性能相比原始的三节点集群增加三倍。
当然，在同样数量的节点上增加更多的复制分片并不能提高性能，因为这样做的话平均每个分片的所占有的硬件资源就减少了，你需要增加硬件来提高吞吐量。
不过这些额外的复制节点使我们有更多的冗余：通过以上对节点的设置，我们能够承受两个节点故障而不丢失数据。

## 4. NoSQL 数据库
Elasticsearch 可以作为数据库使用，主要依赖于它的以下特性：
1. 默认在索引中保存原始数据，并可获取。这个主要依赖 Lucene 的store功能。
2. 实现了translog，提供了实时的数据读取能力以及完备的数据持久化能力（在服务器异常挂掉的情况下依然不会丢数据）。
3. Elasticsearch 的dynamic-mapping相当于根据用户提交的数据，动态检测字段类型，自动给数据库表建立表结构，所以它叫做schema-free。
4. 丰富的QueryDSL功能。Elasticsearch 的query语法基本上和sql对等的，除了join查询，以及嵌套临时表查询不能支持。另外group by这种查询可以通过其aggregation实现。Elasticsearch 提供的aggregation能力非常强大，其生态圈里的 Kibana 主要就是依赖aggregation来实现数据分析以及可视化的。

## 5. DSL及aggs
1. Elasticsearch提供丰富且灵活的查询语言叫做DSL查询(Query DSL)，它允许你构建更加复杂、强大的查询。DSL(Domain Specific Language特定领域语言)以JSON请求体的形式出现。

```js
GET /megacorp/employee/_search
{
    "query" : {
        "filtered" : {
            "filter" : { // 过滤器(filter)
                "range" : {
                    "age" : { "gt" : 30 }
                }
            },
            "query" : {
                "match" : {  // match
                    "last_name" : "smith"
                }
            }
        }
    }
}
```
2. Elasticsearch有一个功能叫做聚合(aggregations)，它允许你在数据上生成复杂的分析统计。它很像SQL中的GROUP BY但是功能更强大。

```js
// 统计每种兴趣下职员的平均年龄
GET /megacorp/employee/_search
{
    "aggs" : {
        "all_interests" : {
            "terms" : { "field" : "interests" },
            "aggs" : {
                "avg_age" : {
                    "avg" : { "field" : "age" }
                }
            }
        }
    }
}
```
## 6. 分布式的特性
Elasticsearch为分布式而生，而且它的设计隐藏了分布式本身的复杂性。以下这些操作都是在底层自动完成的：
1. 将你的文档分区到不同的容器或者分片(shards)中，它们可以存在于一个或多个节点中。
2. 将分片均匀的分配到各个节点，对索引和搜索做负载均衡。
3. 冗余每一个分片，防止硬件故障造成的数据丢失。
4. 将集群中任意一个节点上的请求路由到相应数据所在的节点。
5. 无论是增加节点，还是移除节点，分片都可以做到无缝的扩展和迁移。
